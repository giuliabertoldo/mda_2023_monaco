{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from data import df\n",
    "import pickle\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.result_timestamp = pd.to_datetime(df.result_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the features we have decided not to use in the models\n",
    "df = df.drop(['lc_temp_qcl0', 'lc_temp_qcl1', 'lc_temp_qcl2', 'lc_temp_qcl3', 'result_timestamp','lat','lon'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe for the features and one for the target variable, laeq\n",
    "X = df.loc[:, df.columns != 'laeq']\n",
    "y = df.loc[:,'laeq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test and training sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps we want to include in our pipeline\n",
    "numerical_cols = ['lc_dwptemp', 'lc_rainin', 'lc_dailyrain', 'lc_windspeed', 'count']\n",
    "\n",
    "categorical_cols = ['description', 'hour', 'month', 'day_of_week', 'night_of_week']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', categorical_transformer, categorical_cols),\n",
    "    ('num', numerical_transformer, numerical_cols)\n",
    "],\n",
    "remainder='passthrough',\n",
    "verbose_feature_names_out = False,\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', [])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the different models we want to compare\n",
    "grid = [{'classifier':[RandomForestRegressor(), Ridge(), SVR()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the grid search\n",
    "gridSearch = GridSearchCV(pipe, grid, scoring='neg_root_mean_squared_error', n_jobs = -1, verbose=1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the search to our training data\n",
    "gridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best model as selected by the grid search\n",
    "print(gridSearch.best_score_)\n",
    "gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the best model to predict on the test data\n",
    "preds = gridSearch.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate performance measures\n",
    "mse = mean_squared_error(y_val, preds, squared=True)\n",
    "r2 = r2_score(y_val,preds)\n",
    "mae = median_absolute_error(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameters we want to tune and the ranges over which to do so\n",
    "\n",
    "n_estimators = Integer(25, 200)\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "max_depth = Integer(2,30)\n",
    "min_samples_split = Integer(2,15)\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': n_estimators,\n",
    "    'classifier__max_features': max_features,\n",
    "    'classifier__max_depth': max_depth,\n",
    "    'classifier__min_samples_split': min_samples_split,\n",
    "    'classifier__bootstrap': bootstrap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the Bayes search\n",
    "bayesSearch = BayesSearchCV(gridSearch.best_estimator_, search_spaces=param_grid, scoring='neg_root_mean_squared_error', n_iter=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit it to the training data\n",
    "bayesSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the best score and the corresponding parameters\n",
    "print(bayesSearch.best_score_)\n",
    "bayesSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test set using the optimised model\n",
    "preds_opt = bayesSearch.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate performance measures\n",
    "mse_opt = mean_squared_error(y_val, preds_opt, squared=True)\n",
    "r2_opt = r2_score(y_val,preds_opt)\n",
    "mae_opt = median_absolute_error(y_val, preds_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare performance measures between tuned and untuned model\n",
    "data = {'grid':[gridSearch.best_score_,mse,r2,mae], 'bayes':[bayesSearch.best_score_,mse_opt,r2_opt,mae_opt]}\n",
    "pd.DataFrame(data=data, index=['-rmse','mse','r2','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "access_key_id = \n",
    "secret_access_key = \n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key_id ,\n",
    "    aws_secret_access_key=secret_access_key,)\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "bucket='mda.project.monaco'\n",
    "key= 'pickle_model.pkl'\n",
    "\n",
    "pickle_byte_obj = pickle.dumps(bayesSearch)\n",
    "\n",
    "s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/Users/christianbutcher/Documents/MDA/project_real/mda_2023_monaco/app/pickle_rf_model.pkl', 'wb') as file:\n",
    "    pickle.dump(pipe, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdaproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
